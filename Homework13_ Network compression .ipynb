{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[{"file_id":"1S7J12rzL4m5BjSk0QqYw2cnrcqP46VuV","timestamp":1701340761219}]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8f85ab10b6a141c2a961a3caa355df7a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7a0388ef17e04638aab828dbc6634c0d","IPY_MODEL_7aa21085a69c4a989cece2676a2eb0a0","IPY_MODEL_e869e09db5dc4ed382ddab706a08e5b2"],"layout":"IPY_MODEL_4e50124253664e72be340a9a25d81531"}},"7a0388ef17e04638aab828dbc6634c0d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_070968e3e0524d5994129fcfa41632f0","placeholder":"​","style":"IPY_MODEL_bc5b34f1ef1f41809ca1659b706cdf23","value":"100%"}},"7aa21085a69c4a989cece2676a2eb0a0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_201d847981144c61adb5248cc4d163fb","max":53,"min":0,"orientation":"horizontal","style":"IPY_MODEL_06bf19929e4e4715826c6aa554c6aa08","value":53}},"e869e09db5dc4ed382ddab706a08e5b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6b96a5ee0fc4849be91b53f31aa803c","placeholder":"​","style":"IPY_MODEL_844036173c014524a9dda33963a4ea7c","value":" 53/53 [00:42&lt;00:00,  1.44it/s]"}},"4e50124253664e72be340a9a25d81531":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"070968e3e0524d5994129fcfa41632f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc5b34f1ef1f41809ca1659b706cdf23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"201d847981144c61adb5248cc4d163fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06bf19929e4e4715826c6aa554c6aa08":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c6b96a5ee0fc4849be91b53f31aa803c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"844036173c014524a9dda33963a4ea7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f153a2dc6404759990f98c4f0914d2c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9de15667c130437bab0aa0181761926a","IPY_MODEL_645ccee5c1b748ec8edda7a3f277a66d","IPY_MODEL_8189acfeb18d453f8b9235709e45a0f1"],"layout":"IPY_MODEL_ccbb84ccc3134f06b08488dfc9446fe0"}},"9de15667c130437bab0aa0181761926a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fb340f8c1b041b2821ec666d3961a80","placeholder":"​","style":"IPY_MODEL_e5b1c376d721437c9647818137fcb03f","value":"100%"}},"645ccee5c1b748ec8edda7a3f277a66d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ec898ce43ea4481813383014ed3e34b","max":155,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f5df60534e364920b389b8119a54da94","value":155}},"8189acfeb18d453f8b9235709e45a0f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0852b692828549288dd66851a4b04513","placeholder":"​","style":"IPY_MODEL_61c9a53cf2e2413da8546a49c335dc2d","value":" 155/155 [01:52&lt;00:00,  2.02it/s]"}},"ccbb84ccc3134f06b08488dfc9446fe0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fb340f8c1b041b2821ec666d3961a80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5b1c376d721437c9647818137fcb03f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ec898ce43ea4481813383014ed3e34b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5df60534e364920b389b8119a54da94":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0852b692828549288dd66851a4b04513":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61c9a53cf2e2413da8546a49c335dc2d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f82b09cfff9495297722a8e632ebf8f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5424b6d09eef459ba0bf9a4c3760f759","IPY_MODEL_1a2beba328894260850733377a947fd0","IPY_MODEL_7fde1fb9aed24af195d4198624e5ae86"],"layout":"IPY_MODEL_97575a34435f417fb7db8e73238daf5b"}},"5424b6d09eef459ba0bf9a4c3760f759":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_919446c542614532833df0e206e9021a","placeholder":"​","style":"IPY_MODEL_7709b309d8c844e58181a7b07a7786f1","value":"100%"}},"1a2beba328894260850733377a947fd0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_40b1ba9cf9be46f8afa7875613c5ddb9","max":54,"min":0,"orientation":"horizontal","style":"IPY_MODEL_09b9ed0e570d4cc09ffe88b8ea2ae8eb","value":54}},"7fde1fb9aed24af195d4198624e5ae86":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1893d359b3e4b56857fe741cd89f45d","placeholder":"​","style":"IPY_MODEL_77757cece36946cabcdc63b8e0423714","value":" 54/54 [00:29&lt;00:00,  2.81it/s]"}},"97575a34435f417fb7db8e73238daf5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"919446c542614532833df0e206e9021a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7709b309d8c844e58181a7b07a7786f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40b1ba9cf9be46f8afa7875613c5ddb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09b9ed0e570d4cc09ffe88b8ea2ae8eb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a1893d359b3e4b56857fe741cd89f45d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77757cece36946cabcdc63b8e0423714":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"85b79e4f70214831b65a0dd864a87a01":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_953d487b505545f9a9110751243a6e07","IPY_MODEL_9e419ce57b3a49bebb20a77456acec80","IPY_MODEL_2c27f83e95b44daca6e55abb2a9805e6"],"layout":"IPY_MODEL_5151f0c75641403b9cdcdbd01b3a8e9f"}},"953d487b505545f9a9110751243a6e07":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82de756f59d44070adb33e0dc6c5d54b","placeholder":"​","style":"IPY_MODEL_3eb419f85e9a4de5818b918ccc125b37","value":" 68%"}},"9e419ce57b3a49bebb20a77456acec80":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2662c0d3ae74c4bb490eb59ef74e9d5","max":155,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e6054c341a174c3f83e1ad4e984b6778","value":105}},"2c27f83e95b44daca6e55abb2a9805e6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84d7042de04f4423854c6da20adade0a","placeholder":"​","style":"IPY_MODEL_e1b6cc731ef44a39a7d22337449dc975","value":" 105/155 [01:09&lt;00:34,  1.46it/s]"}},"5151f0c75641403b9cdcdbd01b3a8e9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82de756f59d44070adb33e0dc6c5d54b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3eb419f85e9a4de5818b918ccc125b37":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2662c0d3ae74c4bb490eb59ef74e9d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6054c341a174c3f83e1ad4e984b6778":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"84d7042de04f4423854c6da20adade0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1b6cc731ef44a39a7d22337449dc975":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Homework 13 - Network Compression\n","\n"],"metadata":{"id":"k_UqVZtpSz5Z"}},{"cell_type":"markdown","source":["## Outline\n","\n","* [Packages](#Packages) - intall some required packages.\n","* [Dataset](#Dataset) - something you need to know about the dataset.\n","* [Configs](#Configs) - the configs of the experiments, you can change some hyperparameters here.\n","* [Architecture_Design](#Architecture_Design) - depthwise and pointwise convolution examples and some useful links.\n","* [Knowledge_Distillation](#Knowledge_Distillation) - KL divergence loss for knowledge distillation and some useful links.\n","* [Training](#Training) - training loop implementation modified from HW3.\n","* [Inference](#Inference) - create submission.csv by using the student_best.ckpt from the previous experiment.\n","\n"],"metadata":{"id":"kYKQ2_nzSz5c"}},{"cell_type":"markdown","source":["### Packages\n","First, we need to import some useful packages. If the torchsummary package are not intalled, please install it via `pip install torchsummary`"],"metadata":{"id":"-nyWIJEoSz5d"}},{"cell_type":"code","source":["# Import some useful packages for this homework\n","import numpy as np\n","import pandas as pd\n","import torch\n","import os\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","from PIL import Image\n","from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset # \"ConcatDataset\" and \"Subset\" are possibly useful\n","from torchvision.datasets import DatasetFolder, VisionDataset\n","from torchsummary import summary\n","from tqdm.auto import tqdm\n","import random\n","\n","# !nvidia-smi # list your current GPU"],"metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:23:27.917792Z","iopub.execute_input":"2022-05-24T10:23:27.918416Z","iopub.status.idle":"2022-05-24T10:23:27.923861Z","shell.execute_reply.started":"2022-05-24T10:23:27.918372Z","shell.execute_reply":"2022-05-24T10:23:27.923187Z"},"trusted":true,"id":"vj5hoKkNSz5e","executionInfo":{"status":"ok","timestamp":1701343107757,"user_tz":-540,"elapsed":10951,"user":{"displayName":"aa a","userId":"00557446232956636033"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["### Configs\n","In this part, you can specify some variables and hyperparameters as your configs."],"metadata":{"id":"LLkfmF7WSz5f"}},{"cell_type":"code","source":["cfg = {\n","    'dataset_root': './food11-hw13',\n","    'save_dir': './outputs',\n","    'exp_name': \"simple_baseline\",\n","    'batch_size': 64,\n","    'lr': 3e-4,\n","    'seed': 20220013,\n","    'loss_fn_type': 'CE', # simple baseline: CE, medium baseline: KD. See the Knowledge_Distillation part for more information.\n","    'weight_decay': 1e-5,\n","    'grad_norm_max': 10,\n","    'n_epochs': 10, # train more steps to pass the medium baseline.\n","    'patience': 300,\n","}"],"metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:23:31.840586Z","iopub.execute_input":"2022-05-24T10:23:31.841156Z","iopub.status.idle":"2022-05-24T10:23:31.845766Z","shell.execute_reply.started":"2022-05-24T10:23:31.841116Z","shell.execute_reply":"2022-05-24T10:23:31.844796Z"},"trusted":true,"id":"OtmYVkobSz5f","executionInfo":{"status":"ok","timestamp":1701343092862,"user_tz":-540,"elapsed":372,"user":{"displayName":"aa a","userId":"00557446232956636033"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["myseed = cfg['seed']  # set a random seed for reproducibility\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(myseed)\n","torch.manual_seed(myseed)\n","random.seed(myseed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(myseed)\n","\n","save_path = os.path.join(cfg['save_dir'], cfg['exp_name']) # create saving directory\n","os.makedirs(save_path, exist_ok=True)\n","\n","# define simple logging functionality\n","log_fw = open(f\"{save_path}/log.txt\", 'w') # open log file to save log outputs\n","def log(text):     # define a logging function to trace the training process\n","    print(text)\n","    log_fw.write(str(text)+'\\n')\n","    log_fw.flush()\n","\n","log(cfg)  # log your configs to the log file"],"metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:23:34.772487Z","iopub.execute_input":"2022-05-24T10:23:34.773042Z","iopub.status.idle":"2022-05-24T10:23:34.782290Z","shell.execute_reply.started":"2022-05-24T10:23:34.772995Z","shell.execute_reply":"2022-05-24T10:23:34.781517Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"-hQgM5oQSz5g","executionInfo":{"status":"ok","timestamp":1701343168281,"user_tz":-540,"elapsed":368,"user":{"displayName":"aa a","userId":"00557446232956636033"}},"outputId":"b32f9f3c-f52a-401b-9d5e-77f618b37c02"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["{'dataset_root': './food11-hw13', 'save_dir': './outputs', 'exp_name': 'simple_baseline', 'batch_size': 64, 'lr': 0.0003, 'seed': 20220013, 'loss_fn_type': 'CE', 'weight_decay': 1e-05, 'grad_norm_max': 10, 'n_epochs': 10, 'patience': 300}\n"]}]},{"cell_type":"markdown","source":["### Dataset\n","We use Food11 dataset for this homework, which is similar to homework3. But remember, Please DO NOT utilize the dataset of HW3. We've modified the dataset, so you should only access the dataset by loading it in this kaggle notebook or through the links provided in the HW13 colab notebooks."],"metadata":{"id":"oXAuqqkHSz5h"}},{"cell_type":"code","source":["# fetch and download the dataset from github (about 1.12G)\n","# !wget https://github.com/virginiakm1988/ML2022-Spring/raw/main/HW13/food11-hw13.tar.gz\n","## backup links:\n","\n","!wget https://github.com/andybi7676/ml2022spring-hw13/raw/main/food11-hw13.tar.gz -O food11-hw13.tar.gz\n","# !gdown '1ijKoNmpike_yjUw8SWRVVWVoMOXXqycj' --output food11-hw13.tar.gz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ERoxWV4VM2K","executionInfo":{"status":"ok","timestamp":1701343198476,"user_tz":-540,"elapsed":27909,"user":{"displayName":"aa a","userId":"00557446232956636033"}},"outputId":"72c37b90-5572-4e04-9cce-c2854eeb439b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-11-30 11:19:31--  https://github.com/andybi7676/ml2022spring-hw13/raw/main/food11-hw13.tar.gz\n","Resolving github.com (github.com)... 140.82.114.3\n","Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://media.githubusercontent.com/media/andybi7676/ml2022spring-hw13/main/food11-hw13.tar.gz [following]\n","--2023-11-30 11:19:31--  https://media.githubusercontent.com/media/andybi7676/ml2022spring-hw13/main/food11-hw13.tar.gz\n","Resolving media.githubusercontent.com (media.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n","Connecting to media.githubusercontent.com (media.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1203320552 (1.1G) [application/octet-stream]\n","Saving to: ‘food11-hw13.tar.gz’\n","\n","food11-hw13.tar.gz  100%[===================>]   1.12G   242MB/s    in 8.4s    \n","\n","2023-11-30 11:19:57 (136 MB/s) - ‘food11-hw13.tar.gz’ saved [1203320552/1203320552]\n","\n"]}]},{"cell_type":"code","source":["# extract the data\n","!tar -xzf ./food11-hw13.tar.gz # Could take some time\n","# !tar -xzvf ./food11-hw13.tar.gz # use this command if you want to checkout the whole process."],"metadata":{"id":"eAC22Jf1WxL9","executionInfo":{"status":"ok","timestamp":1701343211827,"user_tz":-540,"elapsed":13353,"user":{"displayName":"aa a","userId":"00557446232956636033"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["for dirname, _, filenames in os.walk('./food11-hw13'):\n","    if len(filenames) > 0:\n","        print(f\"{dirname}: {len(filenames)} files.\") # Show the file amounts in each split."],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-24T10:03:22.50954Z","iopub.execute_input":"2022-05-24T10:03:22.509792Z","iopub.status.idle":"2022-05-24T10:03:29.344989Z","shell.execute_reply.started":"2022-05-24T10:03:22.509758Z","shell.execute_reply":"2022-05-24T10:03:29.344227Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"_CspVRJESz5h","executionInfo":{"status":"ok","timestamp":1701343211828,"user_tz":-540,"elapsed":8,"user":{"displayName":"aa a","userId":"00557446232956636033"}},"outputId":"5acf8ef2-cfbf-4b65-f85b-be9ba6e38221"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["./food11-hw13: 1 files.\n","./food11-hw13/validation: 3430 files.\n","./food11-hw13/evaluation: 3347 files.\n","./food11-hw13/training: 9866 files.\n"]}]},{"cell_type":"markdown","source":["Next, specify train/test transform for image data augmentation.\n","Torchvision provides lots of useful utilities for image preprocessing, data wrapping as well as data augmentation.\n","\n","Please refer to [PyTorch official website](https://pytorch.org/vision/stable/transforms.html) for details about different transforms. You can also apply the knowledge or experience you learned in HW3."],"metadata":{"id":"_J76I6bTSz5i"}},{"cell_type":"code","source":["normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","# define training/testing transforms\n","test_tfm = transforms.Compose([\n","    # It is not encouraged to modify this part if you are using the provided teacher model. This transform is stardard and good enough for testing.\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    normalize,\n","])\n","\n","train_tfm = transforms.Compose([\n","    # add some useful transform or augmentation here, according to your experience in HW3.\n","    transforms.Resize(256),  # You can change this\n","    transforms.CenterCrop(224), # You can change this, but be aware of that the given teacher model's input size is 224.\n","    # The training input size of the provided teacher model is (3, 224, 224).\n","    # Thus, Input size other then 224 might hurt the performance. please be careful.\n","    transforms.RandomHorizontalFlip(), # You can change this.\n","    transforms.ToTensor(),\n","    normalize,\n","])"],"metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:03:29.347832Z","iopub.execute_input":"2022-05-24T10:03:29.348041Z","iopub.status.idle":"2022-05-24T10:03:29.355565Z","shell.execute_reply.started":"2022-05-24T10:03:29.348014Z","shell.execute_reply":"2022-05-24T10:03:29.354664Z"},"trusted":true,"id":"GYIvuK-RSz5i","executionInfo":{"status":"ok","timestamp":1701343211828,"user_tz":-540,"elapsed":6,"user":{"displayName":"aa a","userId":"00557446232956636033"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class FoodDataset(Dataset):\n","    def __init__(self, path, tfm=test_tfm, files = None):\n","        super().__init__()\n","        self.path = path\n","        self.files = sorted([os.path.join(path,x) for x in os.listdir(path) if x.endswith(\".jpg\")])\n","        if files != None:\n","            self.files = files\n","        print(f\"One {path} sample\",self.files[0])\n","        self.transform = tfm\n","\n","    def __len__(self):\n","        return len(self.files)\n","\n","    def __getitem__(self,idx):\n","        fname = self.files[idx]\n","        im = Image.open(fname)\n","        im = self.transform(im)\n","        try:\n","            label = int(fname.split(\"/\")[-1].split(\"_\")[0])\n","        except:\n","            label = -1 # test has no label\n","        return im,label"],"metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:03:29.35682Z","iopub.execute_input":"2022-05-24T10:03:29.357325Z","iopub.status.idle":"2022-05-24T10:03:29.370053Z","shell.execute_reply.started":"2022-05-24T10:03:29.357285Z","shell.execute_reply":"2022-05-24T10:03:29.369273Z"},"trusted":true,"id":"SsYOy-PBSz5i","executionInfo":{"status":"ok","timestamp":1701343211828,"user_tz":-540,"elapsed":6,"user":{"displayName":"aa a","userId":"00557446232956636033"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Form train/valid dataloaders\n","train_set = FoodDataset(os.path.join(cfg['dataset_root'],\"training\"), tfm=train_tfm)\n","train_loader = DataLoader(train_set, batch_size=cfg['batch_size'], shuffle=True, num_workers=0, pin_memory=True)\n","\n","valid_set = FoodDataset(os.path.join(cfg['dataset_root'], \"validation\"), tfm=test_tfm)\n","valid_loader = DataLoader(valid_set, batch_size=cfg['batch_size'], shuffle=False, num_workers=0, pin_memory=True)"],"metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:03:29.372379Z","iopub.execute_input":"2022-05-24T10:03:29.373093Z","iopub.status.idle":"2022-05-24T10:03:29.417511Z","shell.execute_reply.started":"2022-05-24T10:03:29.373057Z","shell.execute_reply":"2022-05-24T10:03:29.416795Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"PUl030elSz5j","executionInfo":{"status":"ok","timestamp":1701343211828,"user_tz":-540,"elapsed":6,"user":{"displayName":"aa a","userId":"00557446232956636033"}},"outputId":"022bf66a-f936-4cb2-f474-09d31b9fa649"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["One ./food11-hw13/training sample ./food11-hw13/training/0_0.jpg\n","One ./food11-hw13/validation sample ./food11-hw13/validation/0_0.jpg\n"]}]},{"cell_type":"markdown","source":["### Architecture_Design\n","\n","In this homework, you have to design a smaller network and make it perform well. Apparently, a well-designed architecture is crucial for such task. Here, we introduce the depthwise and pointwise convolution. These variants of convolution are some common techniques for architecture design when it comes to network compression.\n","\n","<img src=\"https://i.imgur.com/LFDKHOp.png\" width=400px>\n","\n","* explanation of depthwise and pointwise convolutions:\n","    * [prof. Hung-yi Lee's slides(p.24~p.30, especially p.28)](https://speech.ee.ntu.edu.tw/~hylee/ml/ml2021-course-data/tiny_v7.pdf)"],"metadata":{"id":"Kna5Gp_eSz5j"}},{"cell_type":"code","source":["# Example implementation of Depthwise and Pointwise Convolution\n","def dwpw_conv(in_channels, out_channels, kernel_size, stride=1, padding=0):\n","    return nn.Sequential(\n","        nn.Conv2d(in_channels, in_channels, kernel_size, stride=stride, padding=padding, groups=in_channels), #depthwise convolution\n","        nn.Conv2d(in_channels, out_channels, 1), # pointwise convolution\n","    )"],"metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:03:29.418659Z","iopub.execute_input":"2022-05-24T10:03:29.418928Z","iopub.status.idle":"2022-05-24T10:03:29.423565Z","shell.execute_reply.started":"2022-05-24T10:03:29.418894Z","shell.execute_reply":"2022-05-24T10:03:29.422893Z"},"trusted":true,"id":"chLDiavKSz5j","executionInfo":{"status":"ok","timestamp":1701343334283,"user_tz":-540,"elapsed":896,"user":{"displayName":"aa a","userId":"00557446232956636033"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["* other useful techniques\n","    * [group convolution](https://www.researchgate.net/figure/The-transformations-within-a-layer-in-DenseNets-left-and-CondenseNets-at-training-time_fig2_321325862) (Actually, depthwise convolution is a specific type of group convolution)\n","    * [SqueezeNet](!https://arxiv.org/abs/1602.07360)\n","    * [MobileNet](!https://arxiv.org/abs/1704.04861)\n","    * [ShuffleNet](!https://arxiv.org/abs/1707.01083)\n","    * [Xception](!https://arxiv.org/abs/1610.02357)\n","    * [GhostNet](!https://arxiv.org/abs/1911.11907)\n"],"metadata":{"id":"NfXa-ZBRSz5k"}},{"cell_type":"markdown","source":["After introducing depthwise and pointwise convolutions, let's define the **student network architecture**. Here, we have a very simple network formed by some regular convolution layers and pooling layers. You can replace the regular convolution layers with the depthwise and pointwise convolutions. In this way, you can further increase the depth or the width of your network architecture."],"metadata":{"id":"wo4hrDDESz5k"}},{"cell_type":"code","source":["# Define your student network here. You have to copy-paste this code block to HW13 GradeScope before deadline.\n","# We will use your student network definition to evaluate your results(including the total parameter amount).\n","\n","class StudentNet(nn.Module):\n","    def __init__(self):\n","      super().__init__()\n","\n","      # ---------- TODO ----------\n","      # Modify your model architecture\n","\n","      self.cnn = nn.Sequential(\n","        nn.Conv2d(3, 32, 3),\n","        nn.BatchNorm2d(32),\n","        nn.ReLU(),\n","        nn.Conv2d(32, 32, 3),\n","        nn.BatchNorm2d(32),\n","        nn.ReLU(),\n","        nn.MaxPool2d(2, 2, 0),\n","\n","        nn.Conv2d(32, 64, 3),\n","        nn.BatchNorm2d(64),\n","        nn.ReLU(),\n","        nn.MaxPool2d(2, 2, 0),\n","\n","        nn.Conv2d(64, 100, 3),\n","        nn.BatchNorm2d(100),\n","        nn.ReLU(),\n","        nn.MaxPool2d(2, 2, 0),\n","\n","        # Here we adopt Global Average Pooling for various input size.\n","        nn.AdaptiveAvgPool2d((1, 1)),\n","      )\n","      self.fc = nn.Sequential(\n","        nn.Linear(100, 11),\n","      )\n","\n","    def forward(self, x):\n","      out = self.cnn(x)\n","      out = out.view(out.size()[0], -1)\n","      return self.fc(out)\n","\n","def get_student_model(): # This function should have no arguments so that we can get your student network by directly calling it.\n","    # you can modify or do anything here, just remember to return an nn.Module as your student network.\n","    return StudentNet()\n","\n","# End of definition of your student model and the get_student_model API\n","# Please copy-paste the whole code block, including the get_student_model function."],"metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:03:29.42593Z","iopub.execute_input":"2022-05-24T10:03:29.426336Z","iopub.status.idle":"2022-05-24T10:03:29.437629Z","shell.execute_reply.started":"2022-05-24T10:03:29.426299Z","shell.execute_reply":"2022-05-24T10:03:29.436773Z"},"trusted":true,"id":"DTin50J3Sz5k","executionInfo":{"status":"ok","timestamp":1701343337544,"user_tz":-540,"elapsed":921,"user":{"displayName":"aa a","userId":"00557446232956636033"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["After specifying the student network architecture, please use `torchsummary` package to get information about the network and verify the total number of parameters. Note that the total params of your student network should not exceed the limit (`Total params` in `torchsummary` ≤ 100,000)."],"metadata":{"id":"w99ooIeOSz5k"}},{"cell_type":"code","source":["# DO NOT modify this block and please make sure that this block can run sucessfully.\n","student_model = get_student_model()\n","summary(student_model, (3, 224, 224), device='cpu')\n","# You have to copy&paste the results of this block to HW13 GradeScope."],"metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:03:29.43901Z","iopub.execute_input":"2022-05-24T10:03:29.439472Z","iopub.status.idle":"2022-05-24T10:03:29.725131Z","shell.execute_reply.started":"2022-05-24T10:03:29.439437Z","shell.execute_reply":"2022-05-24T10:03:29.72441Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"ef3hT8W2Sz5k","executionInfo":{"status":"ok","timestamp":1701343341885,"user_tz":-540,"elapsed":916,"user":{"displayName":"aa a","userId":"00557446232956636033"}},"outputId":"a812304b-3e9d-48e6-d81d-a386400405f5"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 32, 222, 222]             896\n","       BatchNorm2d-2         [-1, 32, 222, 222]              64\n","              ReLU-3         [-1, 32, 222, 222]               0\n","            Conv2d-4         [-1, 32, 220, 220]           9,248\n","       BatchNorm2d-5         [-1, 32, 220, 220]              64\n","              ReLU-6         [-1, 32, 220, 220]               0\n","         MaxPool2d-7         [-1, 32, 110, 110]               0\n","            Conv2d-8         [-1, 64, 108, 108]          18,496\n","       BatchNorm2d-9         [-1, 64, 108, 108]             128\n","             ReLU-10         [-1, 64, 108, 108]               0\n","        MaxPool2d-11           [-1, 64, 54, 54]               0\n","           Conv2d-12          [-1, 100, 52, 52]          57,700\n","      BatchNorm2d-13          [-1, 100, 52, 52]             200\n","             ReLU-14          [-1, 100, 52, 52]               0\n","        MaxPool2d-15          [-1, 100, 26, 26]               0\n","AdaptiveAvgPool2d-16            [-1, 100, 1, 1]               0\n","           Linear-17                   [-1, 11]           1,111\n","================================================================\n","Total params: 87,907\n","Trainable params: 87,907\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 99.72\n","Params size (MB): 0.34\n","Estimated Total Size (MB): 100.62\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["# Load provided teacher model (model architecture: resnet18, num_classes=11, test-acc ~= 89.9%)\n","teacher_model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False, num_classes=11)\n","# load state dict\n","teacher_ckpt_path = os.path.join(cfg['dataset_root'], \"resnet18_teacher.ckpt\")\n","teacher_model.load_state_dict(torch.load(teacher_ckpt_path, map_location='cpu'))\n","# Now you already know the teacher model's architecture. You can take advantage of it if you want to pass the strong or boss baseline.\n","# Source code of resnet in pytorch: (https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py)\n","# You can also see the summary of teacher model. There are 11,182,155 parameters totally in the teacher model\n","# summary(teacher_model, (3, 224, 224), device='cpu')"],"metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:03:29.72678Z","iopub.execute_input":"2022-05-24T10:03:29.727038Z","iopub.status.idle":"2022-05-24T10:03:34.185327Z","shell.execute_reply.started":"2022-05-24T10:03:29.727002Z","shell.execute_reply":"2022-05-24T10:03:34.184566Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"EMsCeYkeSz5l","executionInfo":{"status":"ok","timestamp":1701343346701,"user_tz":-540,"elapsed":2495,"user":{"displayName":"aa a","userId":"00557446232956636033"}},"outputId":"114323f1-27be-4820-a1fa-a2da7ffc1981"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["### Knowledge_Distillation\n","\n","<img src=\"https://i.imgur.com/H2aF7Rv.png=100x\" width=\"400px\">\n","\n","Since we have a learned big model, let it teach the other small model. In implementation, let the training target be the prediction of big model instead of the ground truth.\n","\n","**Why it works?**\n","* If the data is not clean, then the prediction of big model could ignore the noise of the data with wrong labeled.\n","* There might have some relations between classes, so soft labels from teacher model might be useful. For example, Number 8 is more similar to 6, 9, 0 than 1, 7.\n","\n","\n","**How to implement?**\n","* $Loss = \\alpha T^2 \\times KL(p || q) + (1-\\alpha)(\\text{Original Cross Entropy Loss}), \\text{where } p=softmax(\\frac{\\text{student's logits}}{T}), \\text{and } q=softmax(\\frac{\\text{teacher's logits}}{T})$\n","* very useful link: [pytorch docs of KLDivLoss with examples](!https://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html)\n","* original paper: [Distilling the Knowledge in a Neural Network](!https://arxiv.org/abs/1503.02531)"],"metadata":{"id":"SssBmJciSz5l"}},{"cell_type":"code","source":["# Implement the loss function with KL divergence loss for knowledge distillation.\n","# You also have to copy-paste this whole block to HW13 GradeScope.\n","def loss_fn_kd(student_logits, labels, teacher_logits, alpha=0.5, temperature=1.0):\n","    # ------------TODO-------------\n","    # Refer to the above formula and finish the loss function for knowkedge distillation using KL divergence loss and CE loss.\n","    # If you have no idea, please take a look at the provided useful link above.\n","    pass"],"metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:03:34.188841Z","iopub.execute_input":"2022-05-24T10:03:34.189265Z","iopub.status.idle":"2022-05-24T10:03:34.194093Z","shell.execute_reply.started":"2022-05-24T10:03:34.189224Z","shell.execute_reply":"2022-05-24T10:03:34.193204Z"},"trusted":true,"id":"twZb0G9-Sz5l","executionInfo":{"status":"ok","timestamp":1701343349142,"user_tz":-540,"elapsed":380,"user":{"displayName":"aa a","userId":"00557446232956636033"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# choose the loss function by the config\n","if cfg['loss_fn_type'] == 'CE':\n","    # For the classification task, we use cross-entropy as the default loss function.\n","    loss_fn = nn.CrossEntropyLoss() # loss function for simple baseline.\n","\n","if cfg['loss_fn_type'] == 'KD': # KD stands for knowledge distillation\n","    loss_fn = loss_fn_kd # implement loss_fn_kd for the report question and the medium baseline.\n","\n","# You can also adopt other types of knowledge distillation techniques for strong and boss baseline, but use function name other than `loss_fn_kd`\n","# For example:\n","# def loss_fn_custom_kd():\n","#     pass\n","# if cfg['loss_fn_type'] == 'custom_kd':\n","#     loss_fn = loss_fn_custom_kd\n","\n","# \"cuda\" only when GPUs are available.\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","log(f\"device: {device}\")\n","\n","# The number of training epochs and patience.\n","n_epochs = cfg['n_epochs']\n","patience = cfg['patience'] # If no improvement in 'patience' epochs, early stop"],"metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:03:34.195253Z","iopub.execute_input":"2022-05-24T10:03:34.195489Z","iopub.status.idle":"2022-05-24T10:03:34.210666Z","shell.execute_reply.started":"2022-05-24T10:03:34.195455Z","shell.execute_reply":"2022-05-24T10:03:34.209911Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"alv2sq_xSz5l","executionInfo":{"status":"ok","timestamp":1701343351052,"user_tz":-540,"elapsed":397,"user":{"displayName":"aa a","userId":"00557446232956636033"}},"outputId":"c770dcef-44ad-479c-dd7d-a299c08c6f80"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["device: cuda\n"]}]},{"cell_type":"markdown","source":["### Training\n","implement training loop for simple baseline, feel free to modify it."],"metadata":{"id":"pI_HZWNFSz5l"}},{"cell_type":"code","source":["# Initialize a model, and put it on the device specified.\n","student_model.to(device)\n","# teacher_model.to(device) # MEDIUM BASELINE\n","\n","# Initialize optimizer, you may fine-tune some hyperparameters such as learning rate on your own.\n","optimizer = torch.optim.Adam(student_model.parameters(), lr=cfg['lr'], weight_decay=cfg['weight_decay'])\n","\n","# Initialize trackers, these are not parameters and should not be changed\n","stale = 0\n","best_acc = 0.0\n","\n","# teacher_model.eval()  # MEDIUM BASELINE\n","for epoch in range(n_epochs):\n","\n","    # ---------- Training ----------\n","    # Make sure the model is in train mode before training.\n","    student_model.train()\n","\n","    # These are used to record information in training.\n","    train_loss = []\n","    train_accs = []\n","    train_lens = []\n","\n","    for batch in tqdm(train_loader):\n","\n","        # A batch consists of image data and corresponding labels.\n","        imgs, labels = batch\n","        imgs = imgs.to(device)\n","        labels = labels.to(device)\n","        #imgs = imgs.half()\n","        #print(imgs.shape,labels.shape)\n","\n","        # Forward the data. (Make sure data and model are on the same device.)\n","#         with torch.no_grad():  # MEDIUM BASELINE\n","#             teacher_logits = teacher_model(imgs)  # MEDIUM BASELINE\n","\n","        logits = student_model(imgs)\n","\n","        # Calculate the cross-entropy loss.\n","        # We don't need to apply softmax before computing cross-entropy as it is done automatically.\n","#         loss = loss_fn(logits, labels, teacher_logits) # MEDIUM BASELINE\n","        loss = loss_fn(logits, labels) # SIMPLE BASELINE\n","        # Gradients stored in the parameters in the previous step should be cleared out first.\n","        optimizer.zero_grad()\n","\n","        # Compute the gradients for parameters.\n","        loss.backward()\n","\n","        # Clip the gradient norms for stable training.\n","        grad_norm = nn.utils.clip_grad_norm_(student_model.parameters(), max_norm=cfg['grad_norm_max'])\n","\n","        # Update the parameters with computed gradients.\n","        optimizer.step()\n","\n","        # Compute the accuracy for current batch.\n","        acc = (logits.argmax(dim=-1) == labels).float().sum()\n","\n","        # Record the loss and accuracy.\n","        train_batch_len = len(imgs)\n","        train_loss.append(loss.item() * train_batch_len)\n","        train_accs.append(acc)\n","        train_lens.append(train_batch_len)\n","\n","    train_loss = sum(train_loss) / sum(train_lens)\n","    train_acc = sum(train_accs) / sum(train_lens)\n","\n","    # Print the information.\n","    log(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n","\n","    # ---------- Validation ----------\n","    # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n","    student_model.eval()\n","\n","    # These are used to record information in validation.\n","    valid_loss = []\n","    valid_accs = []\n","    valid_lens = []\n","\n","    # Iterate the validation set by batches.\n","    for batch in tqdm(valid_loader):\n","\n","        # A batch consists of image data and corresponding labels.\n","        imgs, labels = batch\n","        imgs = imgs.to(device)\n","        labels = labels.to(device)\n","\n","        # We don't need gradient in validation.\n","        # Using torch.no_grad() accelerates the forward process.\n","        with torch.no_grad():\n","            logits = student_model(imgs)\n","#             teacher_logits = teacher_model(imgs) # MEDIUM BASELINE\n","\n","        # We can still compute the loss (but not the gradient).\n","#         loss = loss_fn(logits, labels, teacher_logits) # MEDIUM BASELINE\n","        loss = loss_fn(logits, labels) # SIMPLE BASELINE\n","\n","        # Compute the accuracy for current batch.\n","        acc = (logits.argmax(dim=-1) == labels).float().sum()\n","\n","        # Record the loss and accuracy.\n","        batch_len = len(imgs)\n","        valid_loss.append(loss.item() * batch_len)\n","        valid_accs.append(acc)\n","        valid_lens.append(batch_len)\n","        #break\n","\n","    # The average loss and accuracy for entire validation set is the average of the recorded values.\n","    valid_loss = sum(valid_loss) / sum(valid_lens)\n","    valid_acc = sum(valid_accs) / sum(valid_lens)\n","\n","    # update logs\n","\n","    if valid_acc > best_acc:\n","        log(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f} -> best\")\n","    else:\n","        log(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n","\n","\n","    # save models\n","    if valid_acc > best_acc:\n","        log(f\"Best model found at epoch {epoch}, saving model\")\n","        torch.save(student_model.state_dict(), f\"{save_path}/student_best.ckpt\") # only save best to prevent output memory exceed error\n","        best_acc = valid_acc\n","        stale = 0\n","    else:\n","        stale += 1\n","        if stale > patience:\n","            log(f\"No improvment {patience} consecutive epochs, early stopping\")\n","            break\n","log(\"Finish training\")\n","log_fw.close()"],"metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:03:34.212111Z","iopub.execute_input":"2022-05-24T10:03:34.212548Z","iopub.status.idle":"2022-05-24T10:14:25.519441Z","shell.execute_reply.started":"2022-05-24T10:03:34.21251Z","shell.execute_reply":"2022-05-24T10:14:25.518016Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":554,"referenced_widgets":["6f153a2dc6404759990f98c4f0914d2c","9de15667c130437bab0aa0181761926a","645ccee5c1b748ec8edda7a3f277a66d","8189acfeb18d453f8b9235709e45a0f1","ccbb84ccc3134f06b08488dfc9446fe0","7fb340f8c1b041b2821ec666d3961a80","e5b1c376d721437c9647818137fcb03f","0ec898ce43ea4481813383014ed3e34b","f5df60534e364920b389b8119a54da94","0852b692828549288dd66851a4b04513","61c9a53cf2e2413da8546a49c335dc2d","1f82b09cfff9495297722a8e632ebf8f","5424b6d09eef459ba0bf9a4c3760f759","1a2beba328894260850733377a947fd0","7fde1fb9aed24af195d4198624e5ae86","97575a34435f417fb7db8e73238daf5b","919446c542614532833df0e206e9021a","7709b309d8c844e58181a7b07a7786f1","40b1ba9cf9be46f8afa7875613c5ddb9","09b9ed0e570d4cc09ffe88b8ea2ae8eb","a1893d359b3e4b56857fe741cd89f45d","77757cece36946cabcdc63b8e0423714","85b79e4f70214831b65a0dd864a87a01","953d487b505545f9a9110751243a6e07","9e419ce57b3a49bebb20a77456acec80","2c27f83e95b44daca6e55abb2a9805e6","5151f0c75641403b9cdcdbd01b3a8e9f","82de756f59d44070adb33e0dc6c5d54b","3eb419f85e9a4de5818b918ccc125b37","d2662c0d3ae74c4bb490eb59ef74e9d5","e6054c341a174c3f83e1ad4e984b6778","84d7042de04f4423854c6da20adade0a","e1b6cc731ef44a39a7d22337449dc975"]},"id":"1STfGFhSSz5l","executionInfo":{"status":"error","timestamp":1701343571801,"user_tz":-540,"elapsed":218395,"user":{"displayName":"aa a","userId":"00557446232956636033"}},"outputId":"95a67bbc-0a0c-4b1f-9460-e29716b93c61"},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/155 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f153a2dc6404759990f98c4f0914d2c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[ Train | 001/010 ] loss = 1.96882, acc = 0.32749\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/54 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f82b09cfff9495297722a8e632ebf8f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[ Valid | 001/010 ] loss = 1.86263, acc = 0.34956 -> best\n","Best model found at epoch 0, saving model\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/155 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85b79e4f70214831b65a0dd864a87a01"}},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-d0816f8a0644>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtrain_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# A batch consists of image data and corresponding labels.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-84abd94e865d>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \"\"\"\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Anti-alias option is always applied for PIL Image input. Argument antialias is ignored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Got inappropriate size arg: {size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2190\u001b[0m                 )\n\u001b[1;32m   2191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2192\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["### Inference\n","load the best model of the experiment and generate submission.csv"],"metadata":{"id":"pZDwoTEISz5m"}},{"cell_type":"code","source":["# create dataloader for evaluation\n","eval_set = FoodDataset(os.path.join(cfg['dataset_root'], \"evaluation\"), tfm=test_tfm)\n","eval_loader = DataLoader(eval_set, batch_size=cfg['batch_size'], shuffle=False, num_workers=0, pin_memory=True)"],"metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:14:38.830275Z","iopub.execute_input":"2022-05-24T10:14:38.831095Z","iopub.status.idle":"2022-05-24T10:14:38.849204Z","shell.execute_reply.started":"2022-05-24T10:14:38.831041Z","shell.execute_reply":"2022-05-24T10:14:38.848517Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"QHeuiLSDSz5m","executionInfo":{"status":"ok","timestamp":1653472855809,"user_tz":-480,"elapsed":20,"user":{"displayName":"Liang-Hsuan Tseng","userId":"00589876776041785069"}},"outputId":"c9be140f-c084-4223-b167-abcf3a931092"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["One ./food11-hw13/evaluation sample ./food11-hw13/evaluation/0000.jpg\n"]}]},{"cell_type":"code","source":["# Load model from {exp_name}/student_best.ckpt\n","student_model_best = get_student_model() # get a new student model to avoid reference before assignment.\n","ckpt_path = f\"{save_path}/student_best.ckpt\" # the ckpt path of the best student model.\n","student_model_best.load_state_dict(torch.load(ckpt_path, map_location='cpu')) # load the state dict and set it to the student model\n","student_model_best.to(device) # set the student model to device\n","\n","# Start evaluate\n","student_model_best.eval()\n","eval_preds = [] # storing predictions of the evaluation dataset\n","\n","# Iterate the validation set by batches.\n","for batch in tqdm(eval_loader):\n","    # A batch consists of image data and corresponding labels.\n","    imgs, _ = batch\n","    # We don't need gradient in evaluation.\n","    # Using torch.no_grad() accelerates the forward process.\n","    with torch.no_grad():\n","        logits = student_model_best(imgs.to(device))\n","        preds = list(logits.argmax(dim=-1).squeeze().cpu().numpy())\n","    # loss and acc can not be calculated because we do not have the true labels of the evaluation set.\n","    eval_preds += preds\n","\n","def pad4(i):\n","    return \"0\"*(4-len(str(i))) + str(i)\n","\n","# Save prediction results\n","ids = [pad4(i) for i in range(0,len(eval_set))]\n","categories = eval_preds\n","\n","df = pd.DataFrame()\n","df['Id'] = ids\n","df['Category'] = categories\n","df.to_csv(f\"{save_path}/submission.csv\", index=False) # now you can download the submission.csv and upload it to the kaggle competition."],"metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:14:38.850823Z","iopub.execute_input":"2022-05-24T10:14:38.851086Z","iopub.status.idle":"2022-05-24T10:15:22.633143Z","shell.execute_reply.started":"2022-05-24T10:14:38.851051Z","shell.execute_reply":"2022-05-24T10:15:22.632222Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["8f85ab10b6a141c2a961a3caa355df7a","7a0388ef17e04638aab828dbc6634c0d","7aa21085a69c4a989cece2676a2eb0a0","e869e09db5dc4ed382ddab706a08e5b2","4e50124253664e72be340a9a25d81531","070968e3e0524d5994129fcfa41632f0","bc5b34f1ef1f41809ca1659b706cdf23","201d847981144c61adb5248cc4d163fb","06bf19929e4e4715826c6aa554c6aa08","c6b96a5ee0fc4849be91b53f31aa803c","844036173c014524a9dda33963a4ea7c"]},"id":"6BsLuZLkSz5m","executionInfo":{"status":"ok","timestamp":1653472898632,"user_tz":-480,"elapsed":42835,"user":{"displayName":"Liang-Hsuan Tseng","userId":"00589876776041785069"}},"outputId":"758863c1-4789-4f1f-d801-1237a3656c6a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/53 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f85ab10b6a141c2a961a3caa355df7a"}},"metadata":{}}]},{"cell_type":"markdown","source":["> Don't forget to answer the report questions on GradeScope!"],"metadata":{"id":"998GNALevLAe"}}]}